-- Update the app_category enum to match the new categories
ALTER TYPE app_category RENAME TO app_category_old;

CREATE TYPE app_category AS ENUM (
  'software_engineering',
  'frontend_ui', 
  'ai_ml',
  'cloud_devops',
  'database_data',
  'it_systems',
  'security_cyber'
);

-- Update the questions table to use the new enum
ALTER TABLE questions ALTER COLUMN category TYPE app_category USING 
  CASE category::text
    WHEN 'software' THEN 'software_engineering'::app_category
    WHEN 'ai' THEN 'ai_ml'::app_category
    WHEN 'cloud' THEN 'cloud_devops'::app_category
    WHEN 'data' THEN 'database_data'::app_category
    WHEN 'cyber' THEN 'security_cyber'::app_category
    ELSE 'software_engineering'::app_category
  END;

-- Update the question_categories table to use the new enum
ALTER TABLE question_categories ALTER COLUMN category TYPE app_category USING 
  CASE category::text
    WHEN 'software' THEN 'software_engineering'::app_category
    WHEN 'ai' THEN 'ai_ml'::app_category
    WHEN 'cloud' THEN 'cloud_devops'::app_category
    WHEN 'data' THEN 'database_data'::app_category
    WHEN 'cyber' THEN 'security_cyber'::app_category
    ELSE 'software_engineering'::app_category
  END;

-- Drop the old enum
DROP TYPE app_category_old;

-- Insert sample questions for Software Engineering / Full-Stack Dev
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('Two Sum Problem', 'Coding', 'Easy', 'Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.', 'javascript', 'function twoSum(nums, target)', 'function twoSum(nums, target) {\n    const map = new Map();\n    for (let i = 0; i < nums.length; i++) {\n        const complement = target - nums[i];\n        if (map.has(complement)) {\n            return [map.get(complement), i];\n        }\n        map.set(nums[i], i);\n    }\n    return [];\n}', '[{"input": [[2,7,11,15], 9], "expected": [0,1]}, {"input": [[3,2,4], 6], "expected": [1,2]}]', 'software_engineering'),
('Reverse Linked List', 'Coding', 'Easy', 'Given the head of a singly linked list, reverse the list, and return the reversed list.', 'javascript', 'function reverseList(head)', 'function reverseList(head) {\n    let prev = null;\n    let current = head;\n    while (current !== null) {\n        let next = current.next;\n        current.next = prev;\n        prev = current;\n        current = next;\n    }\n    return prev;\n}', '[{"input": [1,2,3,4,5], "expected": [5,4,3,2,1]}]', 'software_engineering'),
('Valid Parentheses', 'Coding', 'Easy', 'Given a string s containing just the characters ''('', '')'', ''{'', ''}'', ''['' and '']'', determine if the input string is valid.', 'javascript', 'function isValid(s)', 'function isValid(s) {\n    const stack = [];\n    const map = {'')'': ''('', ''}'': ''{'', '']'': ''[''};\n    \n    for (let char of s) {\n        if (char in map) {\n            if (stack.length === 0 || stack.pop() !== map[char]) {\n                return false;\n            }\n        } else {\n            stack.push(char);\n        }\n    }\n    \n    return stack.length === 0;\n}', '[{"input": "()", "expected": true}, {"input": "()[]{}", "expected": true}, {"input": "(]", "expected": false}]', 'software_engineering'),
('Maximum Subarray', 'Coding', 'Medium', 'Given an integer array nums, find the contiguous subarray which has the largest sum and return its sum.', 'javascript', 'function maxSubArray(nums)', 'function maxSubArray(nums) {\n    let maxSoFar = nums[0];\n    let maxEndingHere = nums[0];\n    \n    for (let i = 1; i < nums.length; i++) {\n        maxEndingHere = Math.max(nums[i], maxEndingHere + nums[i]);\n        maxSoFar = Math.max(maxSoFar, maxEndingHere);\n    }\n    \n    return maxSoFar;\n}', '[{"input": [-2,1,-3,4,-1,2,1,-5,4], "expected": 6}]', 'software_engineering'),
('Merge Two Sorted Lists', 'Coding', 'Easy', 'Merge two sorted linked lists and return it as a sorted list.', 'javascript', 'function mergeTwoLists(list1, list2)', 'function mergeTwoLists(list1, list2) {\n    const dummy = new ListNode(0);\n    let current = dummy;\n    \n    while (list1 && list2) {\n        if (list1.val <= list2.val) {\n            current.next = list1;\n            list1 = list1.next;\n        } else {\n            current.next = list2;\n            list2 = list2.next;\n        }\n        current = current.next;\n    }\n    \n    current.next = list1 || list2;\n    return dummy.next;\n}', '[{"input": [[1,2,4], [1,3,4]], "expected": [1,1,2,3,4,4]}]', 'software_engineering'),
('System Design Architecture', 'System Design', 'Hard', 'Design a URL shortening service like bit.ly. Consider scalability, availability, and consistency requirements.', '', '', 'Key components: URL encoding service, database design, caching layer, load balancing, analytics. Consider database sharding, CDN usage, and rate limiting.', '[]', 'software_engineering'),
('REST API Design', 'System Design', 'Medium', 'Design a RESTful API for a social media platform. Include user management, posts, comments, and likes.', '', '', 'Endpoints: GET/POST /users, GET/POST /posts, GET/POST /posts/:id/comments, POST /posts/:id/like. Include authentication, pagination, rate limiting.', '[]', 'software_engineering'),
('Microservices Communication', 'Behavioral', 'Medium', 'Explain how you would handle communication between microservices in a distributed system.', '', '', 'Discuss synchronous (REST, GraphQL) vs asynchronous (message queues, event streaming) communication, service discovery, circuit breakers, and monitoring.', '[]', 'software_engineering');

-- Insert sample questions for Frontend Development / UI
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('DOM Manipulation', 'Coding', 'Easy', 'Write a function that changes the text content of all elements with a specific class name.', 'javascript', 'function changeTextByClass(className, newText)', 'function changeTextByClass(className, newText) {\n    const elements = document.getElementsByClassName(className);\n    for (let element of elements) {\n        element.textContent = newText;\n    }\n}', '[{"input": ["test-class", "Hello World"], "expected": "text changed"}]', 'frontend_ui'),
('Event Handling', 'Coding', 'Easy', 'Create a function that adds a click event listener to a button that toggles a CSS class.', 'javascript', 'function addToggleListener(buttonId, targetId, className)', 'function addToggleListener(buttonId, targetId, className) {\n    const button = document.getElementById(buttonId);\n    const target = document.getElementById(targetId);\n    \n    button.addEventListener(''click'', () => {\n        target.classList.toggle(className);\n    });\n}', '[{"input": ["btn", "target", "active"], "expected": "event listener added"}]', 'frontend_ui'),
('CSS Flexbox Layout', 'Coding', 'Medium', 'Write CSS to create a responsive navigation bar using flexbox that collapses on mobile.', 'css', '.navbar { }', '.navbar {\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    padding: 1rem;\n}\n\n.nav-links {\n    display: flex;\n    list-style: none;\n    gap: 2rem;\n}\n\n@media (max-width: 768px) {\n    .nav-links {\n        flex-direction: column;\n        display: none;\n    }\n    \n    .nav-links.active {\n        display: flex;\n    }\n}', '[{"input": "navbar", "expected": "responsive layout"}]', 'frontend_ui'),
('React Component State', 'Coding', 'Medium', 'Create a React component that manages a todo list with add, remove, and toggle functionality.', 'javascript', 'function TodoList()', 'function TodoList() {\n    const [todos, setTodos] = useState([]);\n    const [input, setInput] = useState("");\n    \n    const addTodo = () => {\n        if (input.trim()) {\n            setTodos([...todos, { id: Date.now(), text: input, completed: false }]);\n            setInput("");\n        }\n    };\n    \n    const toggleTodo = (id) => {\n        setTodos(todos.map(todo => \n            todo.id === id ? { ...todo, completed: !todo.completed } : todo\n        ));\n    };\n    \n    const removeTodo = (id) => {\n        setTodos(todos.filter(todo => todo.id !== id));\n    };\n    \n    return (\n        <div>\n            <input value={input} onChange={(e) => setInput(e.target.value)} />\n            <button onClick={addTodo}>Add</button>\n            {todos.map(todo => (\n                <div key={todo.id}>\n                    <span onClick={() => toggleTodo(todo.id)}>{todo.text}</span>\n                    <button onClick={() => removeTodo(todo.id)}>Remove</button>\n                </div>\n            ))}\n        </div>\n    );\n}', '[{"input": "component", "expected": "functional todo list"}]', 'frontend_ui'),
('CSS Grid Layout', 'Coding', 'Medium', 'Create a responsive photo gallery using CSS Grid that adjusts columns based on screen size.', 'css', '.gallery { }', '.gallery {\n    display: grid;\n    grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));\n    gap: 1rem;\n    padding: 1rem;\n}\n\n.gallery img {\n    width: 100%;\n    height: 200px;\n    object-fit: cover;\n    border-radius: 8px;\n}\n\n@media (max-width: 768px) {\n    .gallery {\n        grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));\n    }\n}', '[{"input": "gallery", "expected": "responsive grid"}]', 'frontend_ui'),
('JavaScript Promises', 'Coding', 'Medium', 'Write a function that fetches data from multiple APIs concurrently and handles errors gracefully.', 'javascript', 'async function fetchMultipleAPIs(urls)', 'async function fetchMultipleAPIs(urls) {\n    try {\n        const promises = urls.map(url => fetch(url).then(res => {\n            if (!res.ok) throw new Error(`Failed to fetch ${url}`);\n            return res.json();\n        }));\n        \n        const results = await Promise.allSettled(promises);\n        \n        return results.map((result, index) => ({\n            url: urls[index],\n            status: result.status,\n            data: result.status === ''fulfilled'' ? result.value : null,\n            error: result.status === ''rejected'' ? result.reason.message : null\n        }));\n    } catch (error) {\n        console.error(''Error in fetchMultipleAPIs:'', error);\n        return [];\n    }\n}', '[{"input": ["https://api1.com", "https://api2.com"], "expected": "concurrent fetch results"}]', 'frontend_ui'),
('Accessibility Implementation', 'Behavioral', 'Medium', 'How would you ensure a complex web application is accessible to users with disabilities?', '', '', 'Implement ARIA labels, keyboard navigation, screen reader support, color contrast compliance, focus management, semantic HTML, alt text for images, and regular accessibility audits.', '[]', 'frontend_ui'),
('Performance Optimization', 'Behavioral', 'Hard', 'Describe strategies for optimizing the performance of a React application.', '', '', 'Code splitting, lazy loading, memoization, virtual scrolling, image optimization, bundle analysis, tree shaking, service workers, and efficient re-rendering strategies.', '[]', 'frontend_ui');

-- Continue with more questions for each category...
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
-- AI / Machine Learning questions
('Linear Regression Implementation', 'Coding', 'Medium', 'Implement a simple linear regression algorithm from scratch using gradient descent.', 'python', 'def linear_regression(X, y, learning_rate=0.01, iterations=1000)', 'def linear_regression(X, y, learning_rate=0.01, iterations=1000):\n    m = len(y)\n    theta = np.zeros(X.shape[1])\n    \n    for i in range(iterations):\n        predictions = X.dot(theta)\n        cost = (1/2*m) * np.sum((predictions - y)**2)\n        gradient = (1/m) * X.T.dot(predictions - y)\n        theta -= learning_rate * gradient\n    \n    return theta', '[{"input": "training_data", "expected": "trained_model"}]', 'ai_ml'),
('Decision Tree Classification', 'Coding', 'Hard', 'Implement a basic decision tree classifier with information gain splitting criteria.', 'python', 'class DecisionTree', 'class DecisionTree:\n    def __init__(self, max_depth=None):\n        self.max_depth = max_depth\n    \n    def entropy(self, y):\n        _, counts = np.unique(y, return_counts=True)\n        probabilities = counts / counts.sum()\n        return -np.sum(probabilities * np.log2(probabilities + 1e-10))\n    \n    def information_gain(self, X_column, y, threshold):\n        left_mask = X_column <= threshold\n        right_mask = ~left_mask\n        \n        if len(y[left_mask]) == 0 or len(y[right_mask]) == 0:\n            return 0\n        \n        parent_entropy = self.entropy(y)\n        left_entropy = self.entropy(y[left_mask])\n        right_entropy = self.entropy(y[right_mask])\n        \n        weighted_entropy = (len(y[left_mask]) / len(y)) * left_entropy + (len(y[right_mask]) / len(y)) * right_entropy\n        \n        return parent_entropy - weighted_entropy', '[{"input": "dataset", "expected": "decision_tree"}]', 'ai_ml'),
('Neural Network Basics', 'Coding', 'Hard', 'Implement a simple neural network with one hidden layer using backpropagation.', 'python', 'class NeuralNetwork', 'class NeuralNetwork:\n    def __init__(self, input_size, hidden_size, output_size):\n        self.W1 = np.random.randn(input_size, hidden_size)\n        self.b1 = np.zeros((1, hidden_size))\n        self.W2 = np.random.randn(hidden_size, output_size)\n        self.b2 = np.zeros((1, output_size))\n    \n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n    \n    def forward(self, X):\n        self.z1 = np.dot(X, self.W1) + self.b1\n        self.a1 = self.sigmoid(self.z1)\n        self.z2 = np.dot(self.a1, self.W2) + self.b2\n        self.a2 = self.sigmoid(self.z2)\n        return self.a2', '[{"input": "training_data", "expected": "neural_network"}]', 'ai_ml'),
('Machine Learning Pipeline', 'System Design', 'Hard', 'Design an end-to-end machine learning pipeline for a recommendation system.', '', '', 'Components: data ingestion, feature engineering, model training, model evaluation, deployment, monitoring, A/B testing, feedback loop, and retraining strategies.', '[]', 'ai_ml'),
('Data Preprocessing', 'Coding', 'Medium', 'Write a function to handle missing values, outliers, and feature scaling in a dataset.', 'python', 'def preprocess_data(df)', 'def preprocess_data(df):\n    # Handle missing values\n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    categorical_cols = df.select_dtypes(include=[''object'']).columns\n    \n    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n    df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n    \n    # Handle outliers using IQR method\n    for col in numeric_cols:\n        Q1 = df[col].quantile(0.25)\n        Q3 = df[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower_bound = Q1 - 1.5 * IQR\n        upper_bound = Q3 + 1.5 * IQR\n        df[col] = df[col].clip(lower_bound, upper_bound)\n    \n    # Feature scaling\n    scaler = StandardScaler()\n    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n    \n    return df, scaler', '[{"input": "raw_dataset", "expected": "preprocessed_data"}]', 'ai_ml');

-- Cloud & DevOps questions
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('Docker Containerization', 'Coding', 'Medium', 'Write a Dockerfile for a Node.js application with multi-stage build and security best practices.', 'dockerfile', 'FROM node:alpine', 'FROM node:alpine as builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\n\nFROM node:alpine\nRUN addgroup -g 1001 -S nodejs\nRUN adduser -S nextjs -u 1001\nWORKDIR /app\nCOPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules\nCOPY --chown=nextjs:nodejs . .\nUSER nextjs\nEXPOSE 3000\nCMD ["node", "server.js"]', '[{"input": "nodejs_app", "expected": "containerized_app"}]', 'cloud_devops'),
('Kubernetes Deployment', 'Coding', 'Hard', 'Create a Kubernetes deployment YAML for a microservice with health checks, resource limits, and horizontal pod autoscaling.', 'yaml', 'apiVersion: apps/v1', 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: microservice-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: microservice-app\n  template:\n    metadata:\n      labels:\n        app: microservice-app\n    spec:\n      containers:\n      - name: app\n        image: microservice:latest\n        ports:\n        - containerPort: 8080\n        resources:\n          requests:\n            memory: "128Mi"\n            cpu: "100m"\n          limits:\n            memory: "256Mi"\n            cpu: "200m"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5', '[{"input": "microservice", "expected": "k8s_deployment"}]', 'cloud_devops'),
('CI/CD Pipeline', 'System Design', 'Medium', 'Design a CI/CD pipeline for a web application including testing, security scanning, and deployment strategies.', '', '', 'Stages: source control trigger, build, unit tests, integration tests, security scanning, artifact storage, staging deployment, automated testing, production deployment with blue-green or canary strategies.', '[]', 'cloud_devops'),
('Infrastructure as Code', 'Coding', 'Hard', 'Write a Terraform configuration to provision a scalable web application infrastructure on AWS.', 'hcl', 'resource "aws_instance"', 'resource "aws_vpc" "main" {\n  cidr_block = "10.0.0.0/16"\n  enable_dns_hostnames = true\n  enable_dns_support = true\n}\n\nresource "aws_internet_gateway" "main" {\n  vpc_id = aws_vpc.main.id\n}\n\nresource "aws_subnet" "public" {\n  count = 2\n  vpc_id = aws_vpc.main.id\n  cidr_block = "10.0.${count.index + 1}.0/24"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n}\n\nresource "aws_launch_template" "app" {\n  name_prefix = "app-"\n  image_id = "ami-0abcdef1234567890"\n  instance_type = "t3.micro"\n  \n  vpc_security_group_ids = [aws_security_group.app.id]\n  \n  user_data = base64encode(<<-EOF\n              #!/bin/bash\n              yum update -y\n              yum install -y httpd\n              systemctl start httpd\n              systemctl enable httpd\n              EOF\n  )\n}\n\nresource "aws_autoscaling_group" "app" {\n  name = "app-asg"\n  vpc_zone_identifier = aws_subnet.public[*].id\n  target_group_arns = [aws_lb_target_group.app.arn]\n  health_check_type = "ELB"\n  \n  min_size = 2\n  max_size = 10\n  desired_capacity = 3\n  \n  launch_template {\n    id = aws_launch_template.app.id\n    version = "$Latest"\n  }\n}', '[{"input": "aws_infrastructure", "expected": "terraform_config"}]', 'cloud_devops'),
('Monitoring and Logging', 'System Design', 'Medium', 'Design a comprehensive monitoring and logging strategy for a distributed microservices architecture.', '', '', 'Components: centralized logging (ELK stack), metrics collection (Prometheus), distributed tracing (Jaeger), alerting (AlertManager), dashboards (Grafana), and incident response procedures.', '[]', 'cloud_devops');

-- Database / Data Engineering questions  
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('SQL Query Optimization', 'Coding', 'Medium', 'Write an optimized SQL query to find the top 5 customers by total order value in the last 6 months.', 'sql', 'SELECT ... FROM ...', 'SELECT \n    c.customer_id,\n    c.customer_name,\n    SUM(oi.quantity * oi.unit_price) as total_order_value\nFROM customers c\nINNER JOIN orders o ON c.customer_id = o.customer_id\nINNER JOIN order_items oi ON o.order_id = oi.order_id\nWHERE o.order_date >= DATEADD(month, -6, GETDATE())\nGROUP BY c.customer_id, c.customer_name\nORDER BY total_order_value DESC\nLIMIT 5;', '[{"input": "customer_orders", "expected": "top_5_customers"}]', 'database_data'),
('Database Indexing Strategy', 'System Design', 'Hard', 'Design an indexing strategy for a high-traffic e-commerce database with complex queries.', '', '', 'Consider composite indexes on (category_id, price), (user_id, created_at), full-text indexes on product descriptions, partial indexes for active products, and monitoring index usage statistics.', '[]', 'database_data'),
('Data Pipeline ETL', 'Coding', 'Hard', 'Implement an ETL pipeline that processes streaming data from multiple sources and loads it into a data warehouse.', 'python', 'def etl_pipeline(sources)', 'def etl_pipeline(sources):\n    def extract(source_config):\n        # Extract data from various sources\n        data = []\n        for source in source_config:\n            if source[''type''] == ''api'':\n                response = requests.get(source[''url''])\n                data.extend(response.json())\n            elif source[''type''] == ''database'':\n                conn = psycopg2.connect(source[''connection''])\n                data.extend(pd.read_sql(source[''query''], conn).to_dict(''records''))\n        return data\n    \n    def transform(raw_data):\n        # Clean and transform data\n        df = pd.DataFrame(raw_data)\n        df = df.dropna()\n        df[''processed_at''] = datetime.now()\n        return df\n    \n    def load(processed_data, target_config):\n        # Load into data warehouse\n        engine = create_engine(target_config[''connection''])\n        processed_data.to_sql(\n            target_config[''table''], \n            engine, \n            if_exists=''append'', \n            index=False\n        )\n    \n    raw_data = extract(sources)\n    processed_data = transform(raw_data)\n    load(processed_data, target_config)\n    \n    return {''status'': ''success'', ''records_processed'': len(processed_data)}', '[{"input": "data_sources", "expected": "processed_data"}]', 'database_data'),
('NoSQL vs SQL Design', 'Behavioral', 'Medium', 'When would you choose a NoSQL database over a relational database for a project?', '', '', 'Consider NoSQL for: flexible schema requirements, horizontal scaling needs, document-based data, high write loads, eventual consistency acceptable, and rapid prototyping. SQL for: complex queries, transactions, data integrity, mature ecosystem.', '[]', 'database_data'),
('Data Warehouse Schema', 'System Design', 'Hard', 'Design a data warehouse schema for an analytics platform that handles customer behavior, sales, and inventory data.', '', '', 'Star schema with fact tables (sales_fact, behavior_fact) and dimension tables (customer_dim, product_dim, time_dim). Include slowly changing dimensions, aggregation tables, and partitioning strategies.', '[]', 'database_data');

-- IT / Systems / Support questions
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('System Troubleshooting', 'Behavioral', 'Medium', 'Walk me through how you would troubleshoot a server that is responding slowly to requests.', '', '', 'Check system resources (CPU, memory, disk I/O), network connectivity, application logs, database performance, recent changes, and use monitoring tools to identify bottlenecks.', '[]', 'it_systems'),
('Network Configuration', 'Coding', 'Medium', 'Write a script to configure network settings and test connectivity on a Linux server.', 'bash', '#!/bin/bash', '#!/bin/bash\n\n# Configure network interface\necho "Configuring network interface..."\nifconfig eth0 192.168.1.100 netmask 255.255.255.0\nroute add default gw 192.168.1.1\n\n# Set DNS servers\necho "nameserver 8.8.8.8" > /etc/resolv.conf\necho "nameserver 8.8.4.4" >> /etc/resolv.conf\n\n# Test connectivity\necho "Testing connectivity..."\nping -c 4 8.8.8.8\nif [ $? -eq 0 ]; then\n    echo "Network configuration successful"\nelse\n    echo "Network configuration failed"\n    exit 1\nfi\n\n# Test DNS resolution\nnslookup google.com\necho "Network setup complete"', '[{"input": "server_config", "expected": "network_configured"}]', 'it_systems'),
('Backup and Recovery', 'System Design', 'Hard', 'Design a comprehensive backup and disaster recovery strategy for a critical business application.', '', '', 'Include automated daily backups, offsite storage, recovery time objectives (RTO), recovery point objectives (RPO), testing procedures, documentation, and failover mechanisms.', '[]', 'it_systems'),
('Active Directory Management', 'Coding', 'Medium', 'Write a PowerShell script to create users in Active Directory from a CSV file with error handling.', 'powershell', 'Import-Module ActiveDirectory', 'Import-Module ActiveDirectory\n\n$csvPath = "users.csv"\n$logPath = "user_creation.log"\n\ntry {\n    $users = Import-Csv $csvPath\n    \n    foreach ($user in $users) {\n        try {\n            $userParams = @{\n                Name = $user.Name\n                GivenName = $user.FirstName\n                Surname = $user.LastName\n                SamAccountName = $user.Username\n                UserPrincipalName = "$($user.Username)@domain.com"\n                Path = $user.OU\n                AccountPassword = (ConvertTo-SecureString $user.TempPassword -AsPlainText -Force)\n                Enabled = $true\n            }\n            \n            New-ADUser @userParams\n            Write-Output "Successfully created user: $($user.Username)" | Tee-Object -FilePath $logPath -Append\n            \n        } catch {\n            Write-Error "Failed to create user $($user.Username): $($_.Exception.Message)" | Tee-Object -FilePath $logPath -Append\n        }\n    }\n} catch {\n    Write-Error "Failed to process CSV file: $($_.Exception.Message)"\n}', '[{"input": "user_csv", "expected": "ad_users_created"}]', 'it_systems'),
('System Performance Monitoring', 'Coding', 'Medium', 'Create a monitoring script that alerts when system resources exceed thresholds.', 'python', 'def monitor_system()', 'import psutil\nimport smtplib\nfrom email.mime.text import MIMEText\nimport time\n\ndef monitor_system():\n    # Thresholds\n    CPU_THRESHOLD = 80\n    MEMORY_THRESHOLD = 85\n    DISK_THRESHOLD = 90\n    \n    while True:\n        # Check CPU usage\n        cpu_percent = psutil.cpu_percent(interval=1)\n        \n        # Check memory usage\n        memory = psutil.virtual_memory()\n        memory_percent = memory.percent\n        \n        # Check disk usage\n        disk = psutil.disk_usage(''/'')\n        disk_percent = (disk.used / disk.total) * 100\n        \n        alerts = []\n        \n        if cpu_percent > CPU_THRESHOLD:\n            alerts.append(f"CPU usage high: {cpu_percent}%")\n        \n        if memory_percent > MEMORY_THRESHOLD:\n            alerts.append(f"Memory usage high: {memory_percent}%")\n        \n        if disk_percent > DISK_THRESHOLD:\n            alerts.append(f"Disk usage high: {disk_percent}%")\n        \n        if alerts:\n            send_alert("\\n".join(alerts))\n        \n        time.sleep(60)  # Check every minute\n\ndef send_alert(message):\n    # Send email alert\n    msg = MIMEText(message)\n    msg[''Subject''] = ''System Alert''\n    msg[''From''] = ''monitor@company.com''\n    msg[''To''] = ''admin@company.com''\n    \n    with smtplib.SMTP(''localhost'') as server:\n        server.send_message(msg)', '[{"input": "system_check", "expected": "monitoring_active"}]', 'it_systems');

-- Security / Cybersecurity questions
INSERT INTO questions (title, qtype, difficulty, prompt, language, signature, expected_answer, tests, category) VALUES
('SQL Injection Prevention', 'Coding', 'Medium', 'Write a secure function to query a database that prevents SQL injection attacks.', 'python', 'def secure_user_query(user_id)', 'def secure_user_query(user_id):\n    import sqlite3\n    \n    # Input validation\n    if not isinstance(user_id, int) or user_id <= 0:\n        raise ValueError("Invalid user ID")\n    \n    try:\n        conn = sqlite3.connect("database.db")\n        cursor = conn.cursor()\n        \n        # Use parameterized query to prevent SQL injection\n        query = "SELECT * FROM users WHERE user_id = ?"\n        cursor.execute(query, (user_id,))\n        \n        result = cursor.fetchone()\n        \n        if result:\n            # Don''t return sensitive information\n            return {\n                "user_id": result[0],\n                "username": result[1],\n                "email": result[2],\n                "created_at": result[4]\n            }\n        else:\n            return None\n            \n    except sqlite3.Error as e:\n        print(f"Database error: {e}")\n        return None\n    finally:\n        if conn:\n            conn.close()', '[{"input": 123, "expected": "user_data"}]', 'security_cyber'),
('Password Security Implementation', 'Coding', 'Medium', 'Implement a secure password hashing and verification system with salt.', 'python', 'def hash_password(password)', 'import hashlib\nimport secrets\nimport hmac\n\ndef hash_password(password):\n    # Generate a random salt\n    salt = secrets.token_hex(32)\n    \n    # Hash the password with salt using PBKDF2\n    password_hash = hashlib.pbkdf2_hmac(\n        ''sha256'',\n        password.encode(''utf-8''),\n        salt.encode(''utf-8''),\n        100000  # 100,000 iterations\n    )\n    \n    return salt + password_hash.hex()\n\ndef verify_password(password, stored_hash):\n    # Extract salt from stored hash\n    salt = stored_hash[:64]\n    stored_password_hash = stored_hash[64:]\n    \n    # Hash the provided password with the extracted salt\n    password_hash = hashlib.pbkdf2_hmac(\n        ''sha256'',\n        password.encode(''utf-8''),\n        salt.encode(''utf-8''),\n        100000\n    )\n    \n    # Use constant-time comparison to prevent timing attacks\n    return hmac.compare_digest(stored_password_hash, password_hash.hex())', '[{"input": "secure_password", "expected": "hashed_password"}]', 'security_cyber'),
('Cross-Site Scripting Prevention', 'Coding', 'Medium', 'Write a function to sanitize user input to prevent XSS attacks in web applications.', 'javascript', 'function sanitizeInput(userInput)', 'function sanitizeInput(userInput) {\n    if (typeof userInput !== ''string'') {\n        return '''';\n    }\n    \n    // HTML entity encoding to prevent XSS\n    const entityMap = {\n        ''&'': ''&amp;'',\n        ''<'': ''&lt;'',\n        ''>'': ''&gt;'',\n        ''"'': ''&quot;'',\n        "''": ''&#39;'',\n        ''/'': ''&#x2F;'',\n        ''`'': ''&#x60;'',\n        ''='': ''&#x3D;''\n    };\n    \n    const sanitized = userInput.replace(/[&<>"''`=\\/]/g, function (s) {\n        return entityMap[s];\n    });\n    \n    // Additional sanitization - remove script tags and javascript: protocol\n    return sanitized\n        .replace(/<script[^>]*>.*?<\\/script>/gi, '''')\n        .replace(/javascript:/gi, '''')\n        .replace(/on\\w+=/gi, '''');\n}\n\n// Content Security Policy header should also be implemented\nfunction setCSPHeaders(response) {\n    response.setHeader(\n        ''Content-Security-Policy'',\n        "default-src ''self''; script-src ''self'' ''unsafe-inline''; style-src ''self'' ''unsafe-inline''"\n    );\n}', '[{"input": "<script>alert(''xss'')</script>", "expected": "sanitized_output"}]', 'security_cyber'),
('Security Audit Framework', 'System Design', 'Hard', 'Design a comprehensive security audit framework for a web application.', '', '', 'Include vulnerability scanning, penetration testing, code review processes, compliance checks (OWASP Top 10), access control audits, encryption verification, and incident response procedures.', '[]', 'security_cyber'),
('JWT Token Security', 'Coding', 'Medium', 'Implement secure JWT token generation and validation with proper security measures.', 'javascript', 'function generateJWT(payload)', 'const jwt = require(''jsonwebtoken'');\nconst crypto = require(''crypto'');\n\n// Use strong secret key (should be in environment variables)\nconst JWT_SECRET = process.env.JWT_SECRET || crypto.randomBytes(64).toString(''hex'');\nconst JWT_REFRESH_SECRET = process.env.JWT_REFRESH_SECRET || crypto.randomBytes(64).toString(''hex'');\n\nfunction generateJWT(payload) {\n    // Validate payload\n    if (!payload || !payload.userId) {\n        throw new Error(''Invalid payload'');\n    }\n    \n    // Add security claims\n    const tokenPayload = {\n        ...payload,\n        iat: Math.floor(Date.now() / 1000),\n        exp: Math.floor(Date.now() / 1000) + (15 * 60), // 15 minutes\n        iss: ''your-app-name'',\n        aud: ''your-app-users''\n    };\n    \n    const accessToken = jwt.sign(tokenPayload, JWT_SECRET, {\n        algorithm: ''HS256''\n    });\n    \n    const refreshToken = jwt.sign(\n        { userId: payload.userId, tokenVersion: payload.tokenVersion },\n        JWT_REFRESH_SECRET,\n        { expiresIn: ''7d'', algorithm: ''HS256'' }\n    );\n    \n    return { accessToken, refreshToken };\n}\n\nfunction validateJWT(token) {\n    try {\n        const decoded = jwt.verify(token, JWT_SECRET, {\n            algorithms: [''HS256''],\n            issuer: ''your-app-name'',\n            audience: ''your-app-users''\n        });\n        \n        return { valid: true, payload: decoded };\n    } catch (error) {\n        return { valid: false, error: error.message };\n    }\n}', '[{"input": "user_payload", "expected": "jwt_tokens"}]', 'security_cyber');